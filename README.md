````markdown
# Wannasurf Scraper

A Python-based scraper that extracts structured surfing data from ğŸŒ **[Wannasurf.com](https://www.wannasurf.com/)**, including:
- Continents and countries
- Regions and sub-regions
- Surf spots with environmental conditions, access type, wave quality, swell/wind directions, seasonal data, temperatures, coordinates, and more

ğŸ“¦ Output formats:
- CSV files per region/country
- Excel files per continent with predefined worksheets: `Country`, `Zones`, `Spots`

---

## âš  Legal & Ethical Notice

This tool is intended **strictly for educational and research purposes**.

Before using it:
- You **must ensure compliance with Wannasurfâ€™s Terms of Service**.
- **Do not use data commercially**, redistribute it, or build competing services without explicit written permission from Wannasurf.
- Start with **sample mode**, keep the request rate low, and avoid overloading the site.

---

## ğŸ“ Project structure

```text
.
â”œâ”€â”€ wannasurf_scraper.py         # Main scraper script
â””â”€â”€ (generated during runtime)
    â”œâ”€â”€ output_csv/              # CSV files by region/country
    â””â”€â”€ excel_output/            # Excel files by continent
````

---

## ğŸ”§ Requirements

* Python 3.10+
* pip
* Stable internet connection
* Recommended: **WSL + VS Code**
* Can also work on native Linux/Mac/Windows

---

## ğŸš€ Installation & Usage

### 1ï¸âƒ£ Clone the repository

```bash
git clone <YOUR-REPO-URL> wannasurf-scraper
cd wannasurf-scraper
```

### 2ï¸âƒ£ Create virtual environment and install dependencies

#### Linux / WSL

```bash
python3 -m venv .venv
source .venv/bin/activate

pip install requests beautifulsoup4 xlsxwriter
# Optional:
# pip install pandas
```

#### Windows (PowerShell / CMD)

```bash
python -m venv .venv
.\.venv\Scripts\activate

pip install requests beautifulsoup4 xlsxwriter
```

---

## â–¶ Running the scraper

### ğŸ”¹ Sample Mode (default)

```python
if __name__ == "__main__":
    # When run as a script perform a sampled scrape.
    # Set sample=False for a full scrape.
    main(sample=True)
```

Run:

```bash
python3 wannasurf_scraper.py
# Or on Windows:
# python wannasurf_scraper.py
```

âœ” This will:

* Run a limited extraction (safe mode)
* Create sample CSVs under `output_csv/`
* Create an example Excel file under `excel_output/`

---

### ğŸ”¸ Full Scrape Mode

> âš  Not recommended unless sample mode was successfully tested
> âš  May generate high traffic and many files

Change script:

```python
if __name__ == "__main__":
    main(sample=False)
```

Or run without modifying:

```bash
python3 -c "from wannasurf_scraper import main; main(sample=False)"
```

---

## ğŸ“Š Output Format

### ğŸ“‚ `output_csv/`

```text
USA_California.csv
USA_Hawaii.csv
Israel.csv
...
```

### ğŸ“‘ `excel_output/`

```text
North_America.xlsx
Europe.xlsx
Africa.xlsx
...
```

Each Excel file contains:

| Worksheet | Description                                                             |
| --------- | ----------------------------------------------------------------------- |
| `Country` | One row per country, including summary data and seasonal values         |
| `Zones`   | One row per region, with surf spot count, subzones, seasonal conditions |
| `Spots`   | One row per surf spot, including all extracted parameters               |

ğŸ“Œ Seasons are formatted per two-month period:

```
Jan/Feb - ...
Mar/Apr - ...
...
Nov/Dec - ...
```

---

## âš™ Configuration

| Parameter      | Location          | Description                                                        |
| -------------- | ----------------- | ------------------------------------------------------------------ |
| `delay`        | fetch()           | Request rate limit (default: `0.5s`). Recommended: `1.0â€“1.5s`.     |
| `sample`       | main()            | Set to `True` for safe mode, `False` full data                     |
| Error handling | try/except blocks | Exceptions per country/region are logged but do not stop execution |

---

## â³ Usage Best Practices

âœ” Add delay of **1â€“2 seconds per request**
âœ” Do **not** run the scraper repeatedly in short intervals
âœ” Avoid bypassing anti-scraping protections
âœ” Use realistic User-Agent headers

---

## ğŸ“„ License

```
MIT License

This software is provided "as is", without warranty of any kind.

IMPORTANT NOTICE:
This license applies ONLY to the software/code.
Any data retrieved using this tool from Wannasurf.com is NOT covered by this license
and must comply with Wannasurfâ€™s Terms of Service and any applicable laws.
```

ğŸ“Œ **License summary in README:**

> ğŸ“ **License:** Code is licensed under MIT.
> âš ï¸ Data retrieved using this tool from Wannasurf.com is subject to the websiteâ€™s Terms of Service and is **not covered** by this license.

---

## ğŸ’¡ Optional â€“ `requirements.txt`

```
requests
beautifulsoup4
xlsxwriter
# pandas  # optional
```

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ Final Notes

* First run recommended:

```bash
python3 wannasurf_scraper.py
```

* After validation â†’ switch to:

```bash
main(sample=False)
```

If you plan to use collected data in any form of publication or external project, contact Wannasurf.com to request permission.


```


