# ðŸ„ Wannasurf Scraper - Installation & Usage Guide

A Python-based scraper that extracts structured surfing data from ðŸŒ **[Wannasurf.com](https://www.wannasurf.com/)**, including:
- Continents and countries
- Regions and sub-regions
- Surf spots with environmental conditions, access type, wave quality, swell/wind directions, seasonal data, temperatures, coordinates, and more

ðŸ“¦ Output formats:
- CSV files per region/country
- Excel files per continent with predefined worksheets: `Country`, `Zones`, `Spots`

---

## âš  Legal & Ethical Notice

This tool is intended **strictly for educational and research purposes**.

Before using it:
- You **must ensure compliance with Wannasurfâ€™s Terms of Service**.
- **Do not use data commercially**, redistribute it, or build competing services without explicit written permission from Wannasurf.
- Start with **sample mode**, keep the request rate low, and avoid overloading the site.

---

## ðŸ“ Project structure

```
.
â”œâ”€â”€ wannasurf_scraper.py         # Main scraper script
â””â”€â”€ (generated during runtime)
    â”œâ”€â”€ output_csv/              # CSV files by region/country
    â””â”€â”€ excel_output/            # Excel files by continent
````

---

## ðŸ”§ Requirements

- **Python 3.10+**
- **pip**
- Stable **internet connection**
- Recommended: **WSL + VS Code**
- Works on **Linux / Mac / Windows**

---

## ðŸš€ Installation & Usage

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/dan-maliano/wannasurf_scraper.git
cd wannasurf-scraper
````

---

### 2ï¸âƒ£ Create virtual environment & install dependencies

#### â–¶ Linux / WSL

```bash
python3 -m venv .venv
source .venv/bin/activate

pip install requests beautifulsoup4 xlsxwriter
# Optional:
# pip install pandas
```

#### ðŸªŸ Windows (PowerShell / CMD)

```bash
python -m venv .venv
.\.venv\Scripts\activate

pip install requests beautifulsoup4 xlsxwriter
```

---

## â–¶ Running the Scraper

### ðŸ”¹ Sample Mode (default & recommended first run)

```python
if __name__ == "__main__":
    # When run as a script perform a sampled scrape.
    # Set sample=False for a full scrape.
    main(sample=True)
```

**Run:**

```bash
python3 wannasurf_scraper.py
# Or on Windows:
# python wannasurf_scraper.py
```

âœ” This will:

* Run a limited extraction (safe mode)
* Create **sample CSVs** under `output_csv/`
* Create **sample Excel** under `excel_output/`

---

### ðŸ”¸ Full Scrape Mode

âš ï¸ **Use only after testing sample mode**
âš ï¸ May generate high traffic + large number of files

#### Option A â€” modify script

```python
if __name__ == "__main__":
    main(sample=False)
```

#### Option B â€” run without modifying:

```bash
python3 -c "from wannasurf_scraper import main; main(sample=False)"
```

---

## ðŸ“Š Output Format

### ðŸ“‚ `output_csv/`

```
USA_California.csv
USA_Hawaii.csv
Israel.csv
...
```

### ðŸ“‘ `excel_output/`

```
North_America.xlsx
Europe.xlsx
Africa.xlsx
...
```

| Worksheet   | Description                                                         |
| ----------- | ------------------------------------------------------------------- |
| **Country** | One row per country with summary + seasonal values                  |
| **Zones**   | One row per region â€” spot count, subzones, seasonal data            |
| **Spots**   | One row per surf spot, with full wave/access/environment parameters |

ðŸ“Œ **Seasons format example:**

```
Jan/Feb - ...
Mar/Apr - ...
...
Nov/Dec - ...
```

---

## âš™ Configuration

| Parameter      | Location     | Description                                                    |
| -------------- | ------------ | -------------------------------------------------------------- |
| `delay`        | `fetch()`    | Request rate limit (default: `0.5s`) â†’ Recommended: `1.0â€“1.5s` |
| `sample`       | `main()`     | `True` = safe mode / `False` = full scrape                     |
| Error handling | `try/except` | Errors per region are **logged**, not blocking                 |

---

## â³ Usage Best Practices

âœ” Add delay of **1â€“2 seconds per request**
âœ” Do **not** run scraper repeatedly in short intervals
âœ” Avoid bypassing anti-scraping protections
âœ” Use realistic **User-Agent headers**

---

## ðŸ“„ License

**MIT License**

```
This software is provided "as is", without warranty of any kind.
```

> âš ï¸ **IMPORTANT NOTICE**
> This license applies **only to the code**.
> Any data retrieved from **Wannasurf.com** using this tool is **not covered by this license**
> and must comply with **Wannasurfâ€™s Terms of Service** and **local laws**.

---


